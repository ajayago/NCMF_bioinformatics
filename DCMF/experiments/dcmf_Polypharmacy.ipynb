{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dCMF\n",
    "Example of running the \"dcmf\" module with the use provided parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import time\n",
    "import itertools\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dcmf import dcmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the sample dataset\n",
    "\n",
    "This directory contains a sample synthetic dataset generated for the augmented setting of Fig 1(c) in the [paper](https://arxiv.org/abs/1811.11427).\n",
    "You can download the sample data from [here](https://drive.google.com/open?id=1EFF_kuOIg2aYyOGZY_peX3NziqCSxxP1) and unzip it to the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_no = 1\n",
    "data_dir = f\"../data/Polypharmacy/sample{sample_no}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from data_dir:  ../data/Polypharmacy/sample1/\n"
     ]
    }
   ],
   "source": [
    "#Loads the dataset into a dict\n",
    "#Note: This dataset contains 5-folds for the matrix X_12 (matrix R below)\n",
    "num_folds = 1\n",
    "#\n",
    "pp = pprint.PrettyPrinter()\n",
    "print(\"Loading data from data_dir: \",data_dir)\n",
    "U1 = pkl.load(open(data_dir+\"X_12.pkl\",'rb'))\n",
    "V1 = pkl.load(open(data_dir+\"X_22.pkl\",'rb'))\n",
    "# V1 = pkl.load(open(data_dir+\"X_26.pkl\",'rb'))\n",
    "# W1 = pkl.load(open(data_dir+\"X_53.pkl\",'rb'))\n",
    "R_temp_dict = {}\n",
    "for fold_num in np.arange(1,num_folds+1):\n",
    "    Rtrain = pkl.load(open(data_dir+'/X_11_train_fold_'+str(fold_num)+'.pkl','rb'))\n",
    "    Rtrain = Rtrain\n",
    "    Rtrain_idx = pkl.load(open(data_dir+'/X_11_train_idx_'+str(fold_num)+'.pkl','rb')) \n",
    "    Rtest = pkl.load(open(data_dir+'/X_11_test_fold_'+str(fold_num)+'.pkl','rb'))\n",
    "    Rtest_idx = pkl.load(open(data_dir+'/X_11_test_idx_'+str(fold_num)+'.pkl','rb'))\n",
    "    Rdoublets = pkl.load(open(data_dir+'/R_doublets_'+str(fold_num)+'.pkl','rb'))\n",
    "    R_temp_dict[fold_num] = {\"Rtrain\":Rtrain,\"Rtrain_idx\":Rtrain_idx,\"Rtest\":Rtest,\"Rtest_idx\":Rtest_idx,\"Rdoublets\":Rdoublets}\n",
    "#\n",
    "data_dict = {\"U1\":U1,\"V1\":V1,\"R\":R_temp_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U1.shape:  (645, 837)\n",
      "V1.shape:  (837, 837)\n",
      "R.shape:  (645, 645)\n"
     ]
    }
   ],
   "source": [
    "print(\"U1.shape: \",U1.shape)\n",
    "print(\"V1.shape: \",V1.shape)\n",
    "print(\"R.shape: \",data_dict['R'][1]['Rtrain'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the required data structures\n",
    "\n",
    "Here we construct the data structures required as input to the dcmf API\n",
    "\n",
    "#### *entity matrix relationship graph *\n",
    "\n",
    "- **G**: dict, keys are entity IDs and values are lists of associated matrix IDs\n",
    "\n",
    "#### * training data*\n",
    "- **X_data**: dict, keys are matrix IDs and values are (1) np.array, or (2) dict, (if this matrix is in validation set **X_val**) with validation set IDs as keys & values as np.array\n",
    "- **X_meta**: dict, keys are matrix IDs and values are lists of the 2 associated entity IDs\n",
    "\n",
    "#### *validation data*\n",
    "- **X_val**: dict, keys are IDs of the matrices that are part of validation set and values are dict with validation set IDs as keys and values are (1) scipy.sparse matrix, or (2) list of triplets corresponding to the validation entries (if you would like to perform classification and measure AUC)  \n",
    "**Note**: To perform K folds cross validation, use K validation sets for the corresponsing matrix/matrices. In the example below, we used a single validation set with ID \"1\" for each of the matrices with IDs \"X1\" and \"X2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = {\n",
    "    \"e1\":[\"X1\",\"X2\"],\\\n",
    "    \"e2\":[\"X2\",\"X3\"]}\n",
    "    #\"e6\":[\"X4\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = {\n",
    "    \"X1\":{\"1\":data_dict['R'][1][\"Rtrain\"]},\\\n",
    "    \"X2\":{\"1\":U1},\\\n",
    "    \"X3\":V1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta = {\n",
    "    \"X1\":[\"e1\",\"e1\"],\\\n",
    "    \"X2\":[\"e1\",\"e2\"],\\\n",
    "    \"X3\":[\"e2\",\"e2\"]}\n",
    "    #\"X5\":[\"e5\",\"e3\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rtest_triplets1 = [[1,1,1],[2,2,0]]\n",
    "# Rtest_triplets2 = [[1,1,1],[3,3,0],[1,2,0],[0,1,0],[0,2,0],[0,3,0]]\n",
    "Rtest_triplets1 = [[241, 208, 0], [111, 37, 1]]\n",
    "Rtest_triplets2 = [[1, 159, 1], [0, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = {\n",
    "    \"X1\":{\"1\":Rtest_triplets1},\n",
    "    \"X2\":{\"1\":Rtest_triplets2}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *dCMF network construction - hyperparameters*\n",
    "\n",
    "- **kf**: float, in the range (0,1) \n",
    "- **k**: int, entity representation or encoding size. Refer Appendix A in the [paper](https://arxiv.org/abs/1811.11427) for info about how k and kf are used in the dCMF network construction. \n",
    "- **e_actf**: str, autoencoder's encoding activation function.\n",
    "- **d_actf**: str, autoencoder's decoding activation function. Supported functions are \"tanh\",\"sigma\",\"relu\",\"lrelu\"\n",
    "- **is_linear_last_enc_layer**: bool, True to set linear activation for the bottleneck/encoding generation layer \n",
    "- **is_linear_last_dec_layer**: bool, True to set linear activation for the output/decoding generation layer \n",
    "- **num_chunks**: int, number of training batches to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = 0.5\n",
    "k = 100\n",
    "e_actf = \"tanh\"\n",
    "d_actf = \"tanh\"\n",
    "is_linear_last_enc_layer = False\n",
    "is_linear_last_dec_layer = False\n",
    "num_chunks = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Optimization/training - hyperparamteres*\n",
    "\n",
    "- **learning_rate**: float, Adam optimizer's learning rate\n",
    "- **weight_decay**: float, Adam optimizers's weight decay (L2 penalty)\n",
    "- **max_epochs**: int, maximum number of training epochs at which the training stops \n",
    "- **convg_thres**: float, convergence threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.05\n",
    "max_epochs = 5\n",
    "convg_thres = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Hyperparamteres related to pre-training*\n",
    "\n",
    "- **is_pretrain**: bool, True for pretraining \n",
    "- **pretrain_thres**: bool, pre-training convergence thresholsd\n",
    "- **max_pretrain_epochs**: int, maximum number of pre-training epochs at which the training stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pretrain=True\n",
    "pretrain_thres= 0.1\n",
    "max_pretrain_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Parameters related to validation*\n",
    "\n",
    "- **val_metric**: str, Validation performance metric. Supported metrics: [\"rmse\",\"r@k\",\"p@k\",\"auc\"]. Where,  \n",
    "     *rmse* - Root [mean square error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)  \n",
    "     *r@k* - Recall@k. Refer section 5.2's sub-section \"Evaluation metric\" in the [paper](https://arxiv.org/abs/1811.11427)      \n",
    "     *p@k* - Probability@k. Refer section 5.3's sub-section \"Evaluation metric\" in the [paper](https://arxiv.org/abs/1811.11427)      \n",
    "     *auc* - [Area under the curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
    "    \n",
    "- **is_val_transpose**: bool, True if the reconstructed matrix has to be transposed before computing the validation performance\n",
    "- **at_k**: int, the value of k if the **val_metric** is either \"r@k\" or \"p@k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metric = \"auc\"\n",
    "is_val_transpose = True\n",
    "at_k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *GPU - parameters *\n",
    "\n",
    "- **is_gpu**: bool, True if pytorch tensors storage and operations has to be done in GPU\n",
    "- **gpu_ids**: str, Comma separated string of CUDA GPU ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_gpu = False\n",
    "gpu_ids = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Instantiating the dCMF model...*\n",
    "- Initializes dCMF after validating the input data and the (hyper)parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcmf_base.__init__ - start\n",
      "dcmf_base.__init__ - end\n",
      "#\n",
      "dCMF:\n",
      "---\n",
      "#\n",
      "dCMF: \n",
      "#\n",
      "learning_rate:  0.001\n",
      "weight_decay:  0.05\n",
      "convg_thres:  0.1\n",
      "max_epochs:  5\n",
      "isPretrain:  True\n",
      "pretrain_thres:  0.1\n",
      "max_pretrain_epochs:  2\n",
      "num_chunks:  2\n",
      "k:  100\n",
      "kf:  0.5\n",
      "e_actf:  tanh\n",
      "d_actf:  tanh\n",
      "is_gpu:  False\n",
      "gpu_ids:  1\n",
      "num entities:  2\n",
      "num matrices:  3\n",
      "num_val_sets:  1\n",
      "X_val #matrices:  2\n",
      "val_metric (used only if X_val #matrices > 0):  auc\n",
      "at_k (used only if X_val #matrices > 0 and val_metric is r@k or p@k):  10\n",
      "is_val_transpose:  True\n",
      "is_linear_last_enc_layer:  False\n",
      "is_linear_last_dec_layer:  False\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "dcmf_model = dcmf(G, X_data, X_meta,\\\n",
    "            num_chunks=num_chunks,k=k, kf=kf, e_actf=e_actf, d_actf=d_actf,\\\n",
    "            learning_rate=learning_rate, weight_decay=weight_decay, convg_thres=convg_thres, max_epochs=max_epochs,\\\n",
    "            is_gpu=is_gpu,gpu_ids=gpu_ids,is_pretrain=is_pretrain, pretrain_thres=pretrain_thres,\\\n",
    "            max_pretrain_epochs=max_pretrain_epochs,X_val=X_val,val_metric=val_metric,\\\n",
    "            is_val_transpose=is_val_transpose, at_k=at_k,\\\n",
    "            is_linear_last_enc_layer=is_linear_last_enc_layer,is_linear_last_dec_layer=is_linear_last_dec_layer,num_val_sets=num_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Fitting... *\n",
    "- Performs the input transformation and network construction\n",
    "- (Pre-trains and) trains the model to obtain the entity representations\n",
    "- Reconstruct the input matrices using the entity representations obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## fold_num:  1  ##\n",
      "dcmf_base.__init__ - start\n",
      "dcmf_base.__init__ - end\n",
      "#\n",
      "dCMF: \n",
      "#\n",
      "learning_rate:  0.001\n",
      "weight_decay:  0.05\n",
      "convg_thres:  0.1\n",
      "max_epochs:  5\n",
      "isPretrain:  True\n",
      "pretrain_thres:  0.1\n",
      "max_pretrain_epochs:  2\n",
      "num_chunks:  2\n",
      "k:  100\n",
      "kf:  0.5\n",
      "e_actf:  tanh\n",
      "d_actf:  tanh\n",
      "is_gpu:  False\n",
      "gpu_ids:  1\n",
      "num entities:  2\n",
      "num matrices:  3\n",
      "num_val_sets:  1\n",
      "X_val #matrices:  2\n",
      "val_metric (used only if X_val #matrices > 0):  auc\n",
      "at_k (used only if X_val #matrices > 0 and val_metric is r@k or p@k):  10\n",
      "is_val_transpose:  True\n",
      "is_linear_last_enc_layer:  False\n",
      "is_linear_last_dec_layer:  False\n",
      "#\n",
      "dcmf - model construction - start\n",
      "__input_transformation - start\n",
      "#\n",
      "concatenated-matrix construction...\n",
      "e_id:  e1\n",
      "X_id_list:  ['X1', 'X2']\n",
      "X_id:  X1\n",
      "X[X_id].shape:  (645, 645)\n",
      "X_id:  X2\n",
      "X[X_id].shape:  (645, 837)\n",
      "C_dict[e].shape:  torch.Size([645, 1482])\n",
      "---\n",
      "e_id:  e2\n",
      "X_id_list:  ['X2', 'X3']\n",
      "X_id:  X2\n",
      "X[X_id].shape:  (645, 837)\n",
      "X_id:  X3\n",
      "X[X_id].shape:  (837, 837)\n",
      "C_dict[e].shape:  torch.Size([837, 1482])\n",
      "---\n",
      "#\n",
      "concatenated-matrix chunking...\n",
      "#\n",
      "e_id:  e1 , min_num_datapoints:  645 , num_chunks:  2\n",
      "e_id:  e2 , min_features:  837 , k:  100\n",
      "#\n",
      "e_id:  e1  C_dict[e_id].shape:  torch.Size([645, 1482])\n",
      "C_temp_chunks_list[0].shape:  torch.Size([323, 1482])\n",
      "---\n",
      "e_id:  e2  C_dict[e_id].shape:  torch.Size([837, 1482])\n",
      "C_temp_chunks_list[0].shape:  torch.Size([419, 1482])\n",
      "---\n",
      "#\n",
      "creating pytorch variables of input matrices...\n",
      "#\n",
      "__input_transformation - end\n",
      "__network_construction - start\n",
      "__network_construction - end\n",
      "dcmf - model construction - end\n",
      "#\n",
      "__pretrain - start\n",
      "pretrain epoch:  1  total loss L:  0.3063710182905197  Took  0.4  secs.\n",
      "pretrain epoch:  2  total loss L:  0.3046737313270569  Took  0.2  secs.\n",
      "**pretrain converged**\n",
      "__pretrain - end\n",
      "#\n",
      "dcmf.fit - start\n",
      "epoch:  1  total loss L:  1.2749438881874084  Took  0.2  secs.\n",
      "epoch:  2  total loss L:  0.7518928945064545  Took  0.2  secs.\n",
      "epoch:  3  total loss L:  0.7179931402206421  Took  0.2  secs.\n",
      "**train converged**\n",
      "Computing AUC.\n",
      "Rpred.shape:  (645, 645)\n",
      "Rtest_triplets.shape:  (2, 3)\n",
      "Computing AUC.\n",
      "Rpred.shape:  (837, 645)\n",
      "Rtest_triplets.shape:  (2, 3)\n",
      "#\n",
      "dcmf.fit - end\n"
     ]
    }
   ],
   "source": [
    "dcmf_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime = 1.407777\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "runtime = end_time - start_time\n",
    "runtime_seconds = runtime.total_seconds()\n",
    "print(f\"Total runtime = {runtime_seconds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Result attributes:*\n",
    "- **out_dict_U**:  dict, keys are validation set IDs and values are dict with entity IDs as keys and np.array of entity representations/encodings as values\n",
    "- **out_dict_X_prime**: dict, keys are matrix IDs and values are matrix reconstructions\n",
    "- **out_dict_info**: dict, keys are loss/validation performance attributes and values are corresponding results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['e1', 'e2'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcmf_model.out_dict_U['1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X1', 'X2', 'X3'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcmf_model.out_dict_X_prime['1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'learning_rate': 0.001,\n",
       "  'weight_decay': 0.05,\n",
       "  'convg_thres': 0.1,\n",
       "  'max_epochs': 5,\n",
       "  'is_pretrain': True,\n",
       "  'pretrain_thres': 0.1,\n",
       "  'max_pretrain_epochs': 2,\n",
       "  'num_chunks': 2,\n",
       "  'k': 100,\n",
       "  'kf': 0.5,\n",
       "  'e_actf': 'tanh',\n",
       "  'd_actf': 'tanh',\n",
       "  'is_linear_last_enc_layer': False,\n",
       "  'is_linear_last_dec_layer': False},\n",
       " 'num_val_sets': 1,\n",
       " 'loss_all_folds': {'1': [0.24374531209468842,\n",
       "   0.05814984254539013,\n",
       "   0.2744844853878021,\n",
       "   0.05201802495867014,\n",
       "   0.08959546685218811]},\n",
       " 'loss_all_folds_avg_tuple': [0.24374531209468842,\n",
       "  0.05814984254539013,\n",
       "  0.2744844853878021,\n",
       "  0.05201802495867014,\n",
       "  0.08959546685218811],\n",
       " 'loss_all_folds_avg_sum': 0.7179931318387389,\n",
       " 'val_metric': 'auc',\n",
       " 'val_perf_all_folds': {'1': {'X1': 1.0, 'X2': 0.0}},\n",
       " 'val_perf_all_folds_avg': {'X1': 1.0, 'X2': 0.0},\n",
       " 'val_perf_all_folds_total': {'1': 1.0},\n",
       " 'val_perf_all_folds_total_avg': 1.0,\n",
       " 'E': 2,\n",
       " 'M': 3}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcmf_model.out_dict_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_emb = list(dcmf_model.out_dict_U['1'].values())[0].detach().numpy()\n",
    "protein_emb = list(dcmf_model.out_dict_U['1'].values())[1].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037469</td>\n",
       "      <td>-0.002871</td>\n",
       "      <td>-0.047453</td>\n",
       "      <td>0.021731</td>\n",
       "      <td>0.004482</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>-0.003119</td>\n",
       "      <td>-0.031401</td>\n",
       "      <td>-0.002572</td>\n",
       "      <td>-0.007288</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053783</td>\n",
       "      <td>-0.002145</td>\n",
       "      <td>0.056322</td>\n",
       "      <td>-0.002455</td>\n",
       "      <td>0.007544</td>\n",
       "      <td>0.068918</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>0.021579</td>\n",
       "      <td>0.071950</td>\n",
       "      <td>0.090616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028119</td>\n",
       "      <td>-0.015934</td>\n",
       "      <td>-0.036404</td>\n",
       "      <td>0.026111</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>-0.013816</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>-0.028311</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059636</td>\n",
       "      <td>-0.010584</td>\n",
       "      <td>0.049845</td>\n",
       "      <td>-0.009985</td>\n",
       "      <td>0.020453</td>\n",
       "      <td>0.076722</td>\n",
       "      <td>0.034911</td>\n",
       "      <td>0.022328</td>\n",
       "      <td>0.079960</td>\n",
       "      <td>0.070648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.023684</td>\n",
       "      <td>0.012077</td>\n",
       "      <td>-0.023164</td>\n",
       "      <td>0.028115</td>\n",
       "      <td>-0.029406</td>\n",
       "      <td>0.036939</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>-0.042475</td>\n",
       "      <td>0.025585</td>\n",
       "      <td>0.051752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>0.018043</td>\n",
       "      <td>0.024735</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>0.051268</td>\n",
       "      <td>0.092523</td>\n",
       "      <td>0.013372</td>\n",
       "      <td>-0.038296</td>\n",
       "      <td>0.119723</td>\n",
       "      <td>0.142418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.041088</td>\n",
       "      <td>-0.018027</td>\n",
       "      <td>-0.031374</td>\n",
       "      <td>0.029885</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>-0.015168</td>\n",
       "      <td>-0.011633</td>\n",
       "      <td>-0.021196</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>-0.014079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034100</td>\n",
       "      <td>-0.010318</td>\n",
       "      <td>0.060764</td>\n",
       "      <td>-0.017037</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>0.063797</td>\n",
       "      <td>0.035630</td>\n",
       "      <td>0.032425</td>\n",
       "      <td>0.067154</td>\n",
       "      <td>0.068001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014265</td>\n",
       "      <td>-0.003711</td>\n",
       "      <td>-0.023553</td>\n",
       "      <td>0.025690</td>\n",
       "      <td>0.013118</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>-0.033097</td>\n",
       "      <td>0.021294</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076035</td>\n",
       "      <td>-0.007983</td>\n",
       "      <td>0.026277</td>\n",
       "      <td>-0.012062</td>\n",
       "      <td>0.032528</td>\n",
       "      <td>0.084276</td>\n",
       "      <td>0.039575</td>\n",
       "      <td>0.007110</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.088102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.037469 -0.002871 -0.047453  0.021731  0.004482  0.001917 -0.003119   \n",
       "1  0.028119 -0.015934 -0.036404  0.026111  0.006785 -0.013816 -0.005945   \n",
       "2 -0.023684  0.012077 -0.023164  0.028115 -0.029406  0.036939  0.003427   \n",
       "3  0.041088 -0.018027 -0.031374  0.029885  0.014841 -0.015168 -0.011633   \n",
       "4  0.014265 -0.003711 -0.023553  0.025690  0.013118  0.001724  0.000833   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0 -0.031401 -0.002572 -0.007288  ... -0.053783 -0.002145  0.056322 -0.002455   \n",
       "1 -0.028311  0.006982  0.002888  ... -0.059636 -0.010584  0.049845 -0.009985   \n",
       "2 -0.042475  0.025585  0.051752  ... -0.132905  0.018043  0.024735  0.012498   \n",
       "3 -0.021196  0.000080 -0.014079  ... -0.034100 -0.010318  0.060764 -0.017037   \n",
       "4 -0.033097  0.021294  0.024326  ... -0.076035 -0.007983  0.026277 -0.012062   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.007544  0.068918  0.031889  0.021579  0.071950  0.090616  \n",
       "1  0.020453  0.076722  0.034911  0.022328  0.079960  0.070648  \n",
       "2  0.051268  0.092523  0.013372 -0.038296  0.119723  0.142418  \n",
       "3  0.006775  0.063797  0.035630  0.032425  0.067154  0.068001  \n",
       "4  0.032528  0.084276  0.039575  0.007110  0.089100  0.088102  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_emb_df = pd.DataFrame(drug_emb)\n",
    "drug_emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(645, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_emb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005424</td>\n",
       "      <td>-0.021525</td>\n",
       "      <td>-0.056158</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>-0.040254</td>\n",
       "      <td>-0.030567</td>\n",
       "      <td>0.066402</td>\n",
       "      <td>-0.034854</td>\n",
       "      <td>-0.073128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015135</td>\n",
       "      <td>0.012548</td>\n",
       "      <td>0.033059</td>\n",
       "      <td>-0.043591</td>\n",
       "      <td>-0.003376</td>\n",
       "      <td>0.077068</td>\n",
       "      <td>-0.024012</td>\n",
       "      <td>-0.004733</td>\n",
       "      <td>0.035805</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.007639</td>\n",
       "      <td>-0.019938</td>\n",
       "      <td>-0.055303</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.004257</td>\n",
       "      <td>-0.037856</td>\n",
       "      <td>-0.032009</td>\n",
       "      <td>0.069649</td>\n",
       "      <td>-0.032316</td>\n",
       "      <td>-0.074753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012290</td>\n",
       "      <td>0.012949</td>\n",
       "      <td>0.034559</td>\n",
       "      <td>-0.045345</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>0.087782</td>\n",
       "      <td>-0.021585</td>\n",
       "      <td>-0.004292</td>\n",
       "      <td>0.030925</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.008677</td>\n",
       "      <td>-0.018171</td>\n",
       "      <td>-0.047965</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>-0.035112</td>\n",
       "      <td>-0.029057</td>\n",
       "      <td>0.066526</td>\n",
       "      <td>-0.036876</td>\n",
       "      <td>-0.071788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.013093</td>\n",
       "      <td>0.033886</td>\n",
       "      <td>-0.042733</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.086641</td>\n",
       "      <td>-0.020628</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>0.031092</td>\n",
       "      <td>0.000319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003124</td>\n",
       "      <td>-0.002043</td>\n",
       "      <td>-0.060301</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>-0.044032</td>\n",
       "      <td>-0.027853</td>\n",
       "      <td>0.084707</td>\n",
       "      <td>-0.040400</td>\n",
       "      <td>-0.089960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>-0.003547</td>\n",
       "      <td>0.032409</td>\n",
       "      <td>-0.046702</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.075467</td>\n",
       "      <td>-0.028733</td>\n",
       "      <td>-0.012493</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.006038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003723</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>-0.054740</td>\n",
       "      <td>0.008519</td>\n",
       "      <td>0.006359</td>\n",
       "      <td>-0.044490</td>\n",
       "      <td>-0.032863</td>\n",
       "      <td>0.080093</td>\n",
       "      <td>-0.038024</td>\n",
       "      <td>-0.095464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016555</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>0.038892</td>\n",
       "      <td>-0.046540</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.077670</td>\n",
       "      <td>-0.036770</td>\n",
       "      <td>-0.015933</td>\n",
       "      <td>0.032781</td>\n",
       "      <td>0.008828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.005424 -0.021525 -0.056158  0.003692  0.005364 -0.040254 -0.030567   \n",
       "1 -0.007639 -0.019938 -0.055303  0.003306  0.004257 -0.037856 -0.032009   \n",
       "2 -0.008677 -0.018171 -0.047965  0.002450  0.001075 -0.035112 -0.029057   \n",
       "3 -0.003124 -0.002043 -0.060301  0.003359  0.010372 -0.044032 -0.027853   \n",
       "4  0.003723 -0.000165 -0.054740  0.008519  0.006359 -0.044490 -0.032863   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0  0.066402 -0.034854 -0.073128  ...  0.015135  0.012548  0.033059 -0.043591   \n",
       "1  0.069649 -0.032316 -0.074753  ...  0.012290  0.012949  0.034559 -0.045345   \n",
       "2  0.066526 -0.036876 -0.071788  ...  0.012497  0.013093  0.033886 -0.042733   \n",
       "3  0.084707 -0.040400 -0.089960  ...  0.017299 -0.003547  0.032409 -0.046702   \n",
       "4  0.080093 -0.038024 -0.095464  ...  0.016555 -0.000380  0.038892 -0.046540   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0 -0.003376  0.077068 -0.024012 -0.004733  0.035805  0.000194  \n",
       "1 -0.000204  0.087782 -0.021585 -0.004292  0.030925  0.000584  \n",
       "2  0.002550  0.086641 -0.020628 -0.005945  0.031092  0.000319  \n",
       "3  0.002039  0.075467 -0.028733 -0.012493  0.030595  0.006038  \n",
       "4  0.004328  0.077670 -0.036770 -0.015933  0.032781  0.008828  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot_emb_df = pd.DataFrame(protein_emb)\n",
    "prot_emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot_emb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df = pd.concat([drug_emb_df, prot_emb_df], ignore_index = True, axis = 0)\n",
    "emb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037469</td>\n",
       "      <td>-0.002871</td>\n",
       "      <td>-0.047453</td>\n",
       "      <td>0.021731</td>\n",
       "      <td>0.004482</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>-0.003119</td>\n",
       "      <td>-0.031401</td>\n",
       "      <td>-0.002572</td>\n",
       "      <td>-0.007288</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053783</td>\n",
       "      <td>-0.002145</td>\n",
       "      <td>0.056322</td>\n",
       "      <td>-0.002455</td>\n",
       "      <td>0.007544</td>\n",
       "      <td>0.068918</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>0.021579</td>\n",
       "      <td>0.071950</td>\n",
       "      <td>0.090616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028119</td>\n",
       "      <td>-0.015934</td>\n",
       "      <td>-0.036404</td>\n",
       "      <td>0.026111</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>-0.013816</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>-0.028311</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059636</td>\n",
       "      <td>-0.010584</td>\n",
       "      <td>0.049845</td>\n",
       "      <td>-0.009985</td>\n",
       "      <td>0.020453</td>\n",
       "      <td>0.076722</td>\n",
       "      <td>0.034911</td>\n",
       "      <td>0.022328</td>\n",
       "      <td>0.079960</td>\n",
       "      <td>0.070648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.023684</td>\n",
       "      <td>0.012077</td>\n",
       "      <td>-0.023164</td>\n",
       "      <td>0.028115</td>\n",
       "      <td>-0.029406</td>\n",
       "      <td>0.036939</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>-0.042475</td>\n",
       "      <td>0.025585</td>\n",
       "      <td>0.051752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>0.018043</td>\n",
       "      <td>0.024735</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>0.051268</td>\n",
       "      <td>0.092523</td>\n",
       "      <td>0.013372</td>\n",
       "      <td>-0.038296</td>\n",
       "      <td>0.119723</td>\n",
       "      <td>0.142418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.041088</td>\n",
       "      <td>-0.018027</td>\n",
       "      <td>-0.031374</td>\n",
       "      <td>0.029885</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>-0.015168</td>\n",
       "      <td>-0.011633</td>\n",
       "      <td>-0.021196</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>-0.014079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034100</td>\n",
       "      <td>-0.010318</td>\n",
       "      <td>0.060764</td>\n",
       "      <td>-0.017037</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>0.063797</td>\n",
       "      <td>0.035630</td>\n",
       "      <td>0.032425</td>\n",
       "      <td>0.067154</td>\n",
       "      <td>0.068001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014265</td>\n",
       "      <td>-0.003711</td>\n",
       "      <td>-0.023553</td>\n",
       "      <td>0.025690</td>\n",
       "      <td>0.013118</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>-0.033097</td>\n",
       "      <td>0.021294</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076035</td>\n",
       "      <td>-0.007983</td>\n",
       "      <td>0.026277</td>\n",
       "      <td>-0.012062</td>\n",
       "      <td>0.032528</td>\n",
       "      <td>0.084276</td>\n",
       "      <td>0.039575</td>\n",
       "      <td>0.007110</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.088102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.037469 -0.002871 -0.047453  0.021731  0.004482  0.001917 -0.003119   \n",
       "1  0.028119 -0.015934 -0.036404  0.026111  0.006785 -0.013816 -0.005945   \n",
       "2 -0.023684  0.012077 -0.023164  0.028115 -0.029406  0.036939  0.003427   \n",
       "3  0.041088 -0.018027 -0.031374  0.029885  0.014841 -0.015168 -0.011633   \n",
       "4  0.014265 -0.003711 -0.023553  0.025690  0.013118  0.001724  0.000833   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0 -0.031401 -0.002572 -0.007288  ... -0.053783 -0.002145  0.056322 -0.002455   \n",
       "1 -0.028311  0.006982  0.002888  ... -0.059636 -0.010584  0.049845 -0.009985   \n",
       "2 -0.042475  0.025585  0.051752  ... -0.132905  0.018043  0.024735  0.012498   \n",
       "3 -0.021196  0.000080 -0.014079  ... -0.034100 -0.010318  0.060764 -0.017037   \n",
       "4 -0.033097  0.021294  0.024326  ... -0.076035 -0.007983  0.026277 -0.012062   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.007544  0.068918  0.031889  0.021579  0.071950  0.090616  \n",
       "1  0.020453  0.076722  0.034911  0.022328  0.079960  0.070648  \n",
       "2  0.051268  0.092523  0.013372 -0.038296  0.119723  0.142418  \n",
       "3  0.006775  0.063797  0.035630  0.032425  0.067154  0.068001  \n",
       "4  0.032528  0.084276  0.039575  0.007110  0.089100  0.088102  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"emb_Polypharmacy_sample_{sample_no}.dat\", \"w\") as file:\n",
    "    file.write(\"\\n\")\n",
    "    for idx, row in emb_df.iterrows():\n",
    "        emb = row[:].astype(np.float32)\n",
    "        emb_str = ' '.join(emb.astype(str))\n",
    "        file.write(f'{idx}\\t{emb_str}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
