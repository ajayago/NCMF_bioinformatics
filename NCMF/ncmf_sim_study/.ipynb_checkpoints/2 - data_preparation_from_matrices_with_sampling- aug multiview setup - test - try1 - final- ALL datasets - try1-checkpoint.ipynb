{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import os\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "rng = 3\n",
    "random.seed(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./ncmf_sim_data/dict_name_dataset_1.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_all = pkl.load(open(fname,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dt1', 'ds1', 'ds2', 'ds3', 'dn1', 'dn2', 'dn3'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_all.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User inputs (Values to be modified as per the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X0 (200, 500)\n",
      "Shape of X1 (200, 300)\n",
      "Shape of X2 (200, 400)\n",
      "Shape of X3 (700, 500)\n",
      "Shape of X4 (600, 300)\n",
      "total_entities:  2700\n",
      "E0_size:  200\n",
      "E1_size:  500\n",
      "E2_size:  300\n",
      "E3_size:  400\n",
      "E4_size:  700\n",
      "E5_size:  600\n",
      "Considering X0\n",
      "E0 --> 0\n",
      "E1 --> 200\n",
      "Considering X1\n",
      "E0 --> 0\n",
      "E2 --> 700\n",
      "Considering X2\n",
      "E0 --> 0\n",
      "E3 --> 1000\n",
      "Considering X3\n",
      "E4 --> 1400\n",
      "E1 --> 200\n",
      "Considering X4\n",
      "E5 --> 2100\n",
      "E2 --> 700\n",
      "Offset for samples is {0: 0, 2: 160000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51698/3713062336.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"value\"] = emb_df[\"value\"]\n",
      "/tmp/ipykernel_51698/3713062336.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"left\"] = emb_df[\"left\"].astype(int)\n",
      "/tmp/ipykernel_51698/3713062336.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"right\"] = emb_df[\"right\"].astype(int)\n",
      "/tmp/ipykernel_51698/3713062336.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"link_type\"] = emb_df[\"link_type\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node labels are the same as node types\n",
      "Entity E0\n",
      "Entity E1\n",
      "Entity E2\n",
      "Entity E3\n",
      "Entity E4\n",
      "Entity E5\n",
      "(540, 3)\n",
      "[200, 500, 300, 400, 700, 600]\n",
      "Shape of X0 (200, 500)\n",
      "Shape of X1 (200, 300)\n",
      "Shape of X2 (200, 400)\n",
      "Shape of X3 (700, 500)\n",
      "Shape of X4 (600, 300)\n",
      "total_entities:  2700\n",
      "E0_size:  200\n",
      "E1_size:  500\n",
      "E2_size:  300\n",
      "E3_size:  400\n",
      "E4_size:  700\n",
      "E5_size:  600\n",
      "Considering X0\n",
      "E0 --> 0\n",
      "E1 --> 200\n",
      "Considering X1\n",
      "E0 --> 0\n",
      "E2 --> 700\n",
      "Considering X2\n",
      "E0 --> 0\n",
      "E3 --> 1000\n",
      "Considering X3\n",
      "E4 --> 1400\n",
      "E1 --> 200\n",
      "Considering X4\n",
      "E5 --> 2100\n",
      "E2 --> 700\n",
      "Offset for samples is {0: 0, 2: 160000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51698/3713062336.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"value\"] = emb_df[\"value\"]\n",
      "/tmp/ipykernel_51698/3713062336.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"left\"] = emb_df[\"left\"].astype(int)\n",
      "/tmp/ipykernel_51698/3713062336.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"right\"] = emb_df[\"right\"].astype(int)\n",
      "/tmp/ipykernel_51698/3713062336.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"link_type\"] = emb_df[\"link_type\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node labels are the same as node types\n",
      "Entity E0\n",
      "Entity E1\n",
      "Entity E2\n",
      "Entity E3\n",
      "Entity E4\n",
      "Entity E5\n",
      "(540, 3)\n",
      "[200, 500, 300, 400, 700, 600]\n",
      "Shape of X0 (200, 500)\n",
      "Shape of X1 (200, 300)\n",
      "Shape of X2 (200, 400)\n",
      "Shape of X3 (700, 500)\n",
      "Shape of X4 (600, 300)\n",
      "total_entities:  2700\n",
      "E0_size:  200\n",
      "E1_size:  500\n",
      "E2_size:  300\n",
      "E3_size:  400\n",
      "E4_size:  700\n",
      "E5_size:  600\n",
      "Considering X0\n",
      "E0 --> 0\n",
      "E1 --> 200\n",
      "Considering X1\n",
      "E0 --> 0\n",
      "E2 --> 700\n",
      "Considering X2\n",
      "E0 --> 0\n",
      "E3 --> 1000\n",
      "Considering X3\n",
      "E4 --> 1400\n",
      "E1 --> 200\n",
      "Considering X4\n",
      "E5 --> 2100\n",
      "E2 --> 700\n",
      "Offset for samples is {0: 0, 2: 160000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51698/3713062336.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"value\"] = emb_df[\"value\"]\n",
      "/tmp/ipykernel_51698/3713062336.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"left\"] = emb_df[\"left\"].astype(int)\n",
      "/tmp/ipykernel_51698/3713062336.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"right\"] = emb_df[\"right\"].astype(int)\n",
      "/tmp/ipykernel_51698/3713062336.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"link_type\"] = emb_df[\"link_type\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node labels are the same as node types\n",
      "Entity E0\n",
      "Entity E1\n",
      "Entity E2\n",
      "Entity E3\n",
      "Entity E4\n",
      "Entity E5\n",
      "(540, 3)\n",
      "[200, 500, 300, 400, 700, 600]\n",
      "Shape of X0 (200, 500)\n",
      "Shape of X1 (200, 300)\n",
      "Shape of X2 (200, 400)\n",
      "Shape of X3 (700, 500)\n",
      "Shape of X4 (600, 300)\n",
      "total_entities:  2700\n",
      "E0_size:  200\n",
      "E1_size:  500\n",
      "E2_size:  300\n",
      "E3_size:  400\n",
      "E4_size:  700\n",
      "E5_size:  600\n",
      "Considering X0\n",
      "E0 --> 0\n",
      "E1 --> 200\n",
      "Considering X1\n",
      "E0 --> 0\n",
      "E2 --> 700\n",
      "Considering X2\n",
      "E0 --> 0\n",
      "E3 --> 1000\n",
      "Considering X3\n",
      "E4 --> 1400\n",
      "E1 --> 200\n",
      "Considering X4\n",
      "E5 --> 2100\n",
      "E2 --> 700\n",
      "Offset for samples is {0: 0, 2: 160000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51698/3713062336.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"value\"] = emb_df[\"value\"]\n",
      "/tmp/ipykernel_51698/3713062336.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"left\"] = emb_df[\"left\"].astype(int)\n",
      "/tmp/ipykernel_51698/3713062336.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"right\"] = emb_df[\"right\"].astype(int)\n",
      "/tmp/ipykernel_51698/3713062336.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"link_type\"] = emb_df[\"link_type\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node labels are the same as node types\n",
      "Entity E0\n",
      "Entity E1\n",
      "Entity E2\n",
      "Entity E3\n",
      "Entity E4\n",
      "Entity E5\n",
      "(540, 3)\n",
      "[200, 500, 300, 400, 700, 600]\n",
      "Shape of X0 (200, 500)\n",
      "Shape of X1 (200, 300)\n",
      "Shape of X2 (200, 400)\n",
      "Shape of X3 (700, 500)\n",
      "Shape of X4 (600, 300)\n",
      "total_entities:  2700\n",
      "E0_size:  200\n",
      "E1_size:  500\n",
      "E2_size:  300\n",
      "E3_size:  400\n",
      "E4_size:  700\n",
      "E5_size:  600\n",
      "Considering X0\n",
      "E0 --> 0\n",
      "E1 --> 200\n",
      "Considering X1\n",
      "E0 --> 0\n",
      "E2 --> 700\n",
      "Considering X2\n",
      "E0 --> 0\n",
      "E3 --> 1000\n",
      "Considering X3\n",
      "E4 --> 1400\n",
      "E1 --> 200\n",
      "Considering X4\n",
      "E5 --> 2100\n",
      "E2 --> 700\n",
      "Offset for samples is {0: 0, 2: 160000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51698/3713062336.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"value\"] = emb_df[\"value\"]\n",
      "/tmp/ipykernel_51698/3713062336.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"left\"] = emb_df[\"left\"].astype(int)\n",
      "/tmp/ipykernel_51698/3713062336.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"right\"] = emb_df[\"right\"].astype(int)\n",
      "/tmp/ipykernel_51698/3713062336.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"link_type\"] = emb_df[\"link_type\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node labels are the same as node types\n",
      "Entity E0\n",
      "Entity E1\n",
      "Entity E2\n",
      "Entity E3\n",
      "Entity E4\n",
      "Entity E5\n",
      "(540, 3)\n",
      "[200, 500, 300, 400, 700, 600]\n",
      "Shape of X0 (200, 500)\n",
      "Shape of X1 (200, 300)\n",
      "Shape of X2 (200, 400)\n",
      "Shape of X3 (700, 500)\n",
      "Shape of X4 (600, 300)\n",
      "total_entities:  2700\n",
      "E0_size:  200\n",
      "E1_size:  500\n",
      "E2_size:  300\n",
      "E3_size:  400\n",
      "E4_size:  700\n",
      "E5_size:  600\n",
      "Considering X0\n",
      "E0 --> 0\n",
      "E1 --> 200\n",
      "Considering X1\n",
      "E0 --> 0\n",
      "E2 --> 700\n",
      "Considering X2\n",
      "E0 --> 0\n",
      "E3 --> 1000\n",
      "Considering X3\n",
      "E4 --> 1400\n",
      "E1 --> 200\n",
      "Considering X4\n",
      "E5 --> 2100\n",
      "E2 --> 700\n",
      "Offset for samples is {0: 0, 2: 160000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51698/3713062336.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"value\"] = emb_df[\"value\"]\n",
      "/tmp/ipykernel_51698/3713062336.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"left\"] = emb_df[\"left\"].astype(int)\n",
      "/tmp/ipykernel_51698/3713062336.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"right\"] = emb_df[\"right\"].astype(int)\n",
      "/tmp/ipykernel_51698/3713062336.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"link_type\"] = emb_df[\"link_type\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node labels are the same as node types\n",
      "Entity E0\n",
      "Entity E1\n",
      "Entity E2\n",
      "Entity E3\n",
      "Entity E4\n",
      "Entity E5\n",
      "(540, 3)\n",
      "[200, 500, 300, 400, 700, 600]\n",
      "Shape of X0 (200, 500)\n",
      "Shape of X1 (200, 300)\n",
      "Shape of X2 (200, 400)\n",
      "Shape of X3 (700, 500)\n",
      "Shape of X4 (600, 300)\n",
      "total_entities:  2700\n",
      "E0_size:  200\n",
      "E1_size:  500\n",
      "E2_size:  300\n",
      "E3_size:  400\n",
      "E4_size:  700\n",
      "E5_size:  600\n",
      "Considering X0\n",
      "E0 --> 0\n",
      "E1 --> 200\n",
      "Considering X1\n",
      "E0 --> 0\n",
      "E2 --> 700\n",
      "Considering X2\n",
      "E0 --> 0\n",
      "E3 --> 1000\n",
      "Considering X3\n",
      "E4 --> 1400\n",
      "E1 --> 200\n",
      "Considering X4\n",
      "E5 --> 2100\n",
      "E2 --> 700\n",
      "Offset for samples is {0: 0, 2: 160000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51698/3713062336.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"value\"] = emb_df[\"value\"]\n",
      "/tmp/ipykernel_51698/3713062336.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"left\"] = emb_df[\"left\"].astype(int)\n",
      "/tmp/ipykernel_51698/3713062336.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"right\"] = emb_df[\"right\"].astype(int)\n",
      "/tmp/ipykernel_51698/3713062336.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emb_df[\"link_type\"] = emb_df[\"link_type\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node labels are the same as node types\n",
      "Entity E0\n",
      "Entity E1\n",
      "Entity E2\n",
      "Entity E3\n",
      "Entity E4\n",
      "Entity E5\n",
      "(540, 3)\n",
      "[200, 500, 300, 400, 700, 600]\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in data_dict_all.keys():\n",
    "    #dataset_name = \"dt1\"\n",
    "    data_dict = data_dict_all[dataset_name]\n",
    "    sample_id = 1\n",
    "    data_folder = \"./ncmf_sim_data/\"+dataset_name+\"/\"\n",
    "    all_matrices = [\"X0\",\"X1\",\"X2\",\"X3\",\"X4\"]\n",
    "    entity_mapping = {\"X0\":[\"E0\",\"E1\"],\n",
    "                      \"X1\":[\"E0\",\"E2\"],\n",
    "                      \"X2\":[\"E0\",\"E3\"],\n",
    "                      \"X3\":[\"E4\",\"E1\"],\n",
    "                      \"X4\":[\"E5\",\"E2\"]}\n",
    "    entity_name_mapping = {'E0': \"ent0\", \n",
    "                           \"E1\": \"ent1\", \n",
    "                           \"E2\": \"ent2\",\n",
    "                           \"E3\": \"ent3\",\n",
    "                           \"E4\": \"ent4\",\n",
    "                           \"E5\": \"ent5\"}\n",
    "    target_matrix_index = [0,2]\n",
    "    rng = 3\n",
    "    #\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "    #\n",
    "    # Output files\n",
    "    sampled_node_file = data_folder + f'sampled{sample_id}_node.dat'\n",
    "    sampled_link_file = data_folder + f'sampled{sample_id}_link.dat'\n",
    "    if target_matrix_index == -1:\n",
    "        sampled_link_test_file = data_folder + f'sampled{sample_id}_link.dat.test'\n",
    "    else:\n",
    "        sampled_link_test_files = []\n",
    "        for m in target_matrix_index:\n",
    "            sampled_link_test_files.append(data_folder + f'sampled{sample_id}_link.dat.test.{m}')\n",
    "    sampled_label_file = data_folder + f'sampled{sample_id}_label.dat'\n",
    "    sampled_label_test_file = data_folder + f'sampled{sample_id}_label.dat.test'\n",
    "    sampled_meta_file = data_folder + f'sampled{sample_id}_meta.dat'\n",
    "    sampled_info_file = data_folder + f'sampled{sample_id}_info.dat'\n",
    "    #\n",
    "    sampled_dict_id_idx_file = data_folder + f\"sampled{sample_id}_dict_id_idx.pkl\" \n",
    "    #\n",
    "    for i in range(len(all_matrices)):\n",
    "        #exec(f\"X{i} = pd.read_csv(data_folder + all_matrices[i], header = None).to_numpy()\")\n",
    "        exec(f\"X{i} = data_dict[str({i})]['X']\")\n",
    "        # This block assigns each of the matrices to variables X0, X1, X2,...\n",
    "    #\n",
    "    for i in range(len(all_matrices)):\n",
    "        print(f\"Shape of X{i}\", end = \" \")\n",
    "        exec(f\"print(X{i}.shape)\")\n",
    "    #\n",
    "    # Get entity IDs - uses matrix_entity_similarity to get total number of unique entries\n",
    "    total_entities = 0\n",
    "    matrices_seen = []\n",
    "    for k,v in entity_mapping.items():\n",
    "        if v[0] not in matrices_seen:\n",
    "            matrices_seen.append(v[0])\n",
    "            total_entities += eval(f\"{k}.shape[0]\")\n",
    "            exec(f\"{v[0]}_size = {k}.shape[0]\")\n",
    "        if v[1] not in matrices_seen:\n",
    "            matrices_seen.append(v[1])\n",
    "            total_entities += eval(f\"{k}.shape[1]\")\n",
    "            exec(f\"{v[1]}_size = {k}.shape[1]\")\n",
    "    print(\"total_entities: \",total_entities)\n",
    "    #\n",
    "    entity_df = pd.DataFrame(columns = [\"entity_name\",\"idx\"])\n",
    "    for E_id in matrices_seen:\n",
    "        exec(f\"cur_entity_size = {E_id}_size\")\n",
    "        exec(f\"print('{E_id}_size: ',{E_id}_size)\")\n",
    "        for i in range(cur_entity_size):\n",
    "            entity_df = entity_df.append({\"entity_name\": f\"{E_id}_{i}\",\"idx\":f\"{i}\" }, ignore_index = True)\n",
    "    #\n",
    "    dict_id_idx = entity_df[\"idx\"].astype(int).to_dict()\n",
    "    full_df = pd.DataFrame(columns = [\"left\", \"right\", \"value\", \"link_type\"])\n",
    "    #\n",
    "    for k,v in entity_mapping.items(): # iterate over all matrices\n",
    "        print(f\"Considering {k}\")\n",
    "        link_type = int(k[1:])\n",
    "        total_left_ents_so_far = 0\n",
    "        for m in matrices_seen:\n",
    "            if v[0] == m:\n",
    "                break\n",
    "            else:\n",
    "                total_left_ents_so_far += eval(f\"{m}_size\")\n",
    "        print(f\"{v[0]} --> {total_left_ents_so_far}\")\n",
    "        total_right_ents_so_far = 0\n",
    "        for m in matrices_seen:\n",
    "            if v[1] == m:\n",
    "                break\n",
    "            else:\n",
    "                total_right_ents_so_far += eval(f\"{m}_size\")\n",
    "        print(f\"{v[1]} --> {total_right_ents_so_far}\")\n",
    "    #     for i in range(eval(f\"{v[0]}_size\")):\n",
    "    #         for j in range(eval(f\"{v[1]}_size\")):\n",
    "    #             left_id = i + total_left_ents_so_far\n",
    "    #             right_id = j + total_right_ents_so_far\n",
    "    #             value = eval(f\"{k}[i][j]\")\n",
    "    #             print(f\"left = {left_id}, right = {right_id}, value = {value}\")\n",
    "    #             full_df = full_df.append({\"left\": left_id, \"right\": right_id, \"value\": value, \"link_type\": link_type}, ignore_index = True)\n",
    "        temp_df = pd.DataFrame(columns = [\"left\", \"right\", \"value\", \"link_type\"])\n",
    "        temp_df[\"left\"] = sorted(list(range(total_left_ents_so_far, total_left_ents_so_far + eval(f\"{v[0]}_size\"))) * eval(f\"{v[1]}_size\"))\n",
    "        temp_df[\"right\"] = list(range(total_right_ents_so_far, total_right_ents_so_far + eval(f\"{v[1]}_size\"))) * eval(f\"{v[0]}_size\")\n",
    "        temp_df[\"value\"] = eval(f\"{k}\").flatten()\n",
    "        temp_df[\"link_type\"] = [link_type] * len(temp_df[\"left\"])\n",
    "        full_df = pd.concat([full_df, temp_df], axis = 0, ignore_index = True)\n",
    "    #\n",
    "    np.random.seed(rng)\n",
    "    if target_matrix_index != -1:\n",
    "        sample = {}\n",
    "        for m in range(len(target_matrix_index)):\n",
    "            target_matrix_R_ent_count = eval(f\"X{target_matrix_index[m]}.shape[0]\")\n",
    "            target_matrix_C_ent_count = eval(f\"X{target_matrix_index[m]}.shape[1]\")\n",
    "            sample[target_matrix_index[m]] = np.random.choice(target_matrix_R_ent_count * target_matrix_C_ent_count, int(0.2 * target_matrix_R_ent_count * target_matrix_C_ent_count) , replace = False) # sample 20 % of the data\n",
    "    else:\n",
    "        sample = np.array([]) # no sampling  \n",
    "    #\n",
    "    if target_matrix_index != -1:\n",
    "        offset = {}\n",
    "        for m in range(len(target_matrix_index)):\n",
    "            offset[target_matrix_index[m]] = 0\n",
    "            for i in range(target_matrix_index[m]):\n",
    "                offset[target_matrix_index[m]] += eval(f\"X{i}.shape[0] * X{i}.shape[1]\")\n",
    "    print(f\"Offset for samples is {offset}\")\n",
    "    #\n",
    "    if target_matrix_index != -1:\n",
    "        for m in target_matrix_index:\n",
    "            sample[m] = sample[m] + offset[m]\n",
    "    else:\n",
    "        sample = sample + offset \n",
    "    #\n",
    "    if target_matrix_index != -1:\n",
    "        test_data = pd.DataFrame()\n",
    "        for m in sample.keys():\n",
    "            test_data = pd.concat([test_data, full_df.iloc[sample[m]]], ignore_index=True)\n",
    "    else:\n",
    "        test_data = full_df.iloc[sample]   \n",
    "    #\n",
    "    orig_test_data_size = test_data.shape[0]\n",
    "    #\n",
    "    # Find all entries that are zeros in the test df\n",
    "    zero_test_data = pd.DataFrame(test_data.groupby(\"left\").sum()[\"value\"]).reset_index()\n",
    "    zero_test_data = zero_test_data[zero_test_data[\"value\"] == 0]\n",
    "    #\n",
    "    test_data_np = test_data.to_numpy()\n",
    "    #\n",
    "    # Create link.dat.test\n",
    "    number_of_pairs = 0\n",
    "    for v in test_data.link_type.unique():\n",
    "        link_file_for_lp = open(data_folder + f'sampled{sample_id}_link.dat.test.{v}', \"w+\")\n",
    "        test_data_np = test_data[test_data[\"link_type\"] == v].to_numpy()\n",
    "        for i in range(test_data_np.shape[0]):\n",
    "            number_of_pairs += 1\n",
    "            link_file_for_lp.write(str(int(test_data_np[i][0])) + \"\\t\" + str(int(test_data_np[i][1])) + \"\\t\" + str(test_data_np[i][2]) + \"\\n\")        \n",
    "        link_file_for_lp.close()  \n",
    "    #\n",
    "    if target_matrix_index == -1:\n",
    "        full_df.drop(sample, inplace = True, axis = 0)\n",
    "    else:\n",
    "        for m in sample.keys():\n",
    "            full_df.drop(sample[m], inplace=True, axis=0)    \n",
    "    #\n",
    "    # Create link.dat file\n",
    "    emb_df = full_df[full_df[\"value\"] != 0]\n",
    "    emb_df[\"value\"] = emb_df[\"value\"]\n",
    "    emb_df[\"left\"] = emb_df[\"left\"].astype(int)\n",
    "    emb_df[\"right\"] = emb_df[\"right\"].astype(int)\n",
    "    emb_df[\"link_type\"] = emb_df[\"link_type\"].astype(int)\n",
    "    emb_df = emb_df[[\"left\", \"right\", \"link_type\", \"value\"]]\n",
    "    emb_df.head()    \n",
    "    #\n",
    "    emb_df.to_csv(sampled_link_file, sep=\"\\t\", header=False, index=False)\n",
    "    #\n",
    "    if \"Entity labels\" in entity_df.columns:\n",
    "        isNodeLabelSeparate = True\n",
    "        print(\"Node labels are different from node types\")\n",
    "    else:\n",
    "        isNodeLabelSeparate = False\n",
    "        print(\"Node labels are the same as node types\")\n",
    "    #\n",
    "    count = 0\n",
    "    node_type = []\n",
    "    node_label = []\n",
    "    for entity in matrices_seen:\n",
    "        print(f\"Entity {entity}\")\n",
    "        entity_size = eval(f\"{entity}_size\")\n",
    "        node_type_val = int(entity[1:])\n",
    "        node_type.extend([node_type_val] * entity_size)\n",
    "        if not isNodeLabelSeparate:\n",
    "            node_label.extend([node_type_val] * entity_size)\n",
    "        count += entity_size\n",
    "\n",
    "    entity_df[\"Node label\"] = node_label if not isNodeLabelSeparate else list(entity_df[\"Entity Labels\"])\n",
    "    entity_df[\"Node type\"] = node_type \n",
    "    #\n",
    "    test_labels_df = None\n",
    "    if target_matrix_index != -1:\n",
    "        test_labels_df = entity_df.sample(frac = 0.2, replace = False, random_state = rng)\n",
    "        test_labels_df = test_labels_df[[\"entity_name\", \"Node type\", \"Node label\"]]\n",
    "        test_labels_df.head()\n",
    "    #\n",
    "    if target_matrix_index != -1:\n",
    "        print(test_labels_df.shape)\n",
    "    else:\n",
    "        print(\"No test labels\")\n",
    "    #\n",
    "    if target_matrix_index != -1:\n",
    "        remaining_labels_df = entity_df.drop(test_labels_df.index)\n",
    "        remaining_labels_df = remaining_labels_df[[\"entity_name\", \"Node type\", \"Node label\"]]\n",
    "        remaining_labels_df.head()\n",
    "    else:\n",
    "        remaining_labels_df = entity_df\n",
    "    #\n",
    "    if target_matrix_index != -1:\n",
    "        test_labels_df.to_csv(sampled_label_test_file, sep = \"\\t\", header = False)\n",
    "    else:\n",
    "        !> {sampled_label_test_file}  \n",
    "    #\n",
    "    remaining_labels_df.to_csv(sampled_label_file, sep = \"\\t\", header = False)\n",
    "    #\n",
    "    entity_df[[\"entity_name\", \"Node type\"]].to_csv(sampled_node_file, sep = \"\\t\", header = False)\n",
    "    #\n",
    "    # Getting node counts\n",
    "    node_values = list(entity_df.groupby(\"Node type\").count()[\"entity_name\"])\n",
    "    print(node_values)\n",
    "    #\n",
    "    # Getting link counts\n",
    "    emb_count = list(emb_df.groupby(\"link_type\").count()[\"value\"])\n",
    "    if target_matrix_index != -1:\n",
    "        for m in target_matrix_index:\n",
    "            test_count = list(test_data[test_data[\"link_type\"] == m].groupby(\"link_type\").count()['value'])[0]\n",
    "            emb_count[m] += test_count\n",
    "    #print(emb_count)\n",
    "    #\n",
    "    # Getting label counts\n",
    "    entity_df.groupby([\"Node type\", \"Node label\"]).count()\n",
    "    label_counts = entity_df.groupby(['Node type','Node label']).count().apply(list).to_dict()\n",
    "    #\n",
    "    meta_file_writer = open(sampled_meta_file, \"w+\")\n",
    "\n",
    "    meta_file_writer.write(f\"Node Total: Count {sum(node_values)}\" + \"\\n\")\n",
    "    for i in range(len(node_values)):\n",
    "        meta_file_writer.write(f\"Node Type_{i}: Count {node_values[i]}\" + \"\\n\")\n",
    "    meta_file_writer.write(f\"Edge Total: Count {sum(emb_count)}\" + \"\\n\")\n",
    "    for i in range(len(emb_count)):\n",
    "        meta_file_writer.write(f\"Edge Type_{i}: Count {emb_count[i]}\" + \"\\n\")\n",
    "    meta_file_writer.write(f\"Label Total: Count {sum(label_counts['entity_name'].values())}\" + \"\\n\")\n",
    "\n",
    "    for i in range(len(node_values)):\n",
    "        meta_file_writer.write(f\"Label Class_{i}_Total: Count {node_values[i]}\" + \"\\n\")\n",
    "        for k in sorted(label_counts[\"entity_name\"]):\n",
    "            if k[0] == i:\n",
    "                meta_file_writer.write(f\"Label Class_{k[0]}_Type_{k[1]}: Count {label_counts['entity_name'][k]}\" + \"\\n\")\n",
    "\n",
    "    meta_file_writer.close()\n",
    "    #\n",
    "    info_file_writer = open(sampled_info_file, \"w+\")\n",
    "\n",
    "    info_file_writer.write(\"node.dat\\n\")\n",
    "    info_file_writer.write(\"TYPE\\tMEANING\\n\")\n",
    "    for k, v in entity_name_mapping.items():\n",
    "        info_file_writer.write(f\"{k[1:]}\"+\"\\t\"+f\"{v}\"+\"\\n\")\n",
    "\n",
    "    info_file_writer.write(\"\\n-----------------------------------------------\\n\")\n",
    "\n",
    "    info_file_writer.write(\"link.dat\\n\")\n",
    "    info_file_writer.write(\"LINK\\tSTART\\tEND\\tMEANING\\n\")\n",
    "    for k,v in entity_mapping.items():\n",
    "        info_file_writer.write(f\"{k[1:]}\" + \"\\t\" + f\"{v[0][1:]}\" + \"\\t\" + f\"{v[1][1:]}\" + \"\\t\" + f\"{entity_name_mapping[f'E{int(v[0][1:])}']}\" + \"-and-\" + f\"{entity_name_mapping[f'E{int(v[1][1:])}']}\" + \"\\n\")\n",
    "\n",
    "    info_file_writer.write(\"\\n-----------------------------------------------\\n\")\n",
    "    info_file_writer.write(\"label.dat\\n\")\n",
    "    info_file_writer.write(\"TYPE\\tCLASS\\tMEANING\\n\")\n",
    "    for i in range(len(node_values)):\n",
    "        for k in sorted(label_counts[\"entity_name\"]):\n",
    "            if k[0] == i:\n",
    "                info_file_writer.write(f\"{i}\" + \"\\t\" + f\"{k[1]}\" + \"\\t\" + f\"{entity_name_mapping[f'E{int(k[1])}']}\" + \"\\n\")\n",
    "\n",
    "    info_file_writer.close()   \n",
    "    #\n",
    "    pkl.dump(dict_id_idx, open(sampled_dict_id_idx_file,\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
