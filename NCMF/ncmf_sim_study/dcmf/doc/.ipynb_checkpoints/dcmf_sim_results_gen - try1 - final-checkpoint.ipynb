{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler, maxabs_scale\n",
    "from math import pi\n",
    "from numpy import sin, cos, linspace\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_no = 1\n",
    "data_dir = \"./../../sample_data_NCMF/ncmf_sim_data/\"\n",
    "list_dataset_names = [\"dt1\"]\n",
    "#list_dataset_names = [\"ds1\",\"ds2\",\"ds3\"]\n",
    "#list_dataset_names = ['dt1', 'ds1', 'ds2', 'ds3', 'dn1', 'dn2', 'dn3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_types = {\n",
    "    \"real\": [\"X0\",\"X1\",\"X3\"],\n",
    "    \"binary\": [\"X2\",\"X4\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test_mat_ids = [\"X0\",\"X2\"]\n",
    "list_test_mat_idx = [0,2]\n",
    "#\n",
    "# list_test_mat_ids = [\"X0\"]\n",
    "# list_test_mat_idx = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perf_metrics(sample_no,\\\n",
    "                        data_dir,\\\n",
    "                        list_dataset_names,\\\n",
    "                        matrix_types,\\\n",
    "                        list_test_mat_ids,\\\n",
    "                        list_test_mat_idx\n",
    "                        ):\n",
    "    dict_dname_perf = {}\n",
    "    #\n",
    "    for dataset_name in list_dataset_names:\n",
    "        print(\"dataset_name: \",dataset_name)\n",
    "        dict_dname_perf[dataset_name] = {}\n",
    "        #\n",
    "        out_dir_recons = data_dir + \"/dcmf/out/\" + dataset_name + \"/\"\n",
    "        fname_recons = out_dir_recons + \"dict_out_dcmf.pkl\"\n",
    "        dict_out_dcmf = pkl.load(open(fname_recons,\"rb\"))\n",
    "        #\n",
    "        data_dir_gt = data_dir + \"/\" + dataset_name + \"/\"\n",
    "        #\n",
    "        sampled_dict_id_idx_file = data_dir_gt + f\"sampled{sample_no}_dict_id_idx.pkl\"\n",
    "        dict_id_idx = pkl.load(open(sampled_dict_id_idx_file,\"rb\"))\n",
    "        #\n",
    "        for i in np.arange(len(list_test_mat_idx)):       \n",
    "            test_mat_idx = list_test_mat_idx[i]\n",
    "            test_mat_id = list_test_mat_ids[i]\n",
    "            #\n",
    "            X_pred = dict_out_dcmf[\"X\"+str(int(test_mat_idx))] \n",
    "            #\n",
    "            fname_list_gt = data_dir_gt + \"sampled1_link.dat.test.\"+str(test_mat_idx)\n",
    "            df_list_gt = pd.read_csv(fname_list_gt,sep=\"\\t\",header=None)\n",
    "            df_list_gt.columns = [\"i_idx\",\"j_idx\",\"value\"]\n",
    "            #\n",
    "            list_gt_vals = []\n",
    "            list_pred_vals = []\n",
    "            for idx,row in df_list_gt.iterrows():\n",
    "                i = int(dict_id_idx[row[\"i_idx\"]])\n",
    "                j = int(dict_id_idx[row[\"j_idx\"]])\n",
    "                #\n",
    "                cur_val_gt = row[\"value\"]\n",
    "                list_gt_vals.append(cur_val_gt)\n",
    "                #\n",
    "                cur_val_pred = X_pred[i,j]\n",
    "                list_pred_vals.append(cur_val_pred)\n",
    "            #\n",
    "            print(\"mat_idx:\",test_mat_idx,\", list_gt_vals - min: \",np.min(list_gt_vals),\", max: \",np.max(list_gt_vals))\n",
    "            print(\"mat_idx:\",test_mat_idx,\", list_pred_vals - min: \",np.min(list_pred_vals),\", max: \",np.max(list_pred_vals))\n",
    "            #\n",
    "            if test_mat_id in matrix_types[\"real\"]:\n",
    "                eval_mat_dtype = \"real\"\n",
    "            elif test_mat_id in matrix_types[\"binary\"]:\n",
    "                eval_mat_dtype = \"binary\"\n",
    "            else:\n",
    "                assert False    \n",
    "            #\n",
    "            if eval_mat_dtype == \"real\":\n",
    "                cur_perf = mean_squared_error(list_gt_vals,list_pred_vals)\n",
    "                cur_perf_metric = \"mse\"\n",
    "            elif eval_mat_dtype == \"binary\":\n",
    "                cur_perf = roc_auc_score(list_gt_vals,list_pred_vals)\n",
    "                cur_perf_metric = \"auc\"\n",
    "            else:\n",
    "                assert False\n",
    "            #\n",
    "            dict_dname_perf[dataset_name][test_mat_idx] = {\n",
    "                \"perf\":cur_perf,\n",
    "                \"perf_metric\":cur_perf_metric\n",
    "            }\n",
    "        print(\"###\")\n",
    "    #\n",
    "    return dict_dname_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name:  dt1\n",
      "mat_idx: 0 , list_gt_vals - min:  -0.5877524709314255 , max:  0.9999363818319802\n",
      "mat_idx: 0 , list_pred_vals - min:  -0.08822639 , max:  0.37984884\n",
      "mat_idx: 2 , list_gt_vals - min:  0.0 , max:  1.0\n",
      "mat_idx: 2 , list_pred_vals - min:  -1.3921316 , max:  1.6225966\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "dict_perf = get_perf_metrics(sample_no,\\\n",
    "                        data_dir,\\\n",
    "                        list_dataset_names,\\\n",
    "                        matrix_types,\\\n",
    "                        list_test_mat_ids,\\\n",
    "                        list_test_mat_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'perf': 0.17425615565671224, 'perf_metric': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'perf': 0.547909432562855, 'perf_metric': 'auc'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 dt1\n",
       "0  {'perf': 0.17425615565671224, 'perf_metric': '...\n",
       "2  {'perf': 0.547909432562855, 'perf_metric': 'auc'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dict_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt1': {0: {'perf': 0.17425615565671224, 'perf_metric': 'mse'},\n",
       "  2: {'perf': 0.547909432562855, 'perf_metric': 'auc'}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
